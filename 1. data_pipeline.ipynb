{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning objectives:\n",
    "Data Pipeline as an efficient methodology\n",
    "\n",
    "why it matters:\n",
    "for experimentation purpose. \n",
    "\n",
    "in this phase, we will \n",
    "collect, \n",
    "LOAD,\n",
    "clean (missing values, duplicate), \n",
    "splitting (train and test), \n",
    "and validate data.\n",
    "\n",
    "\n",
    "in this way, we will have an efficient steps.\n",
    "kalau pengen pakaid dataset lain, udah enak \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: imblearn in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: kaggle in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (1.6.17)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (4.67.0)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (2.2.2)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/csenv/lib/python3.12/site-packages (from requests->kaggle) (3.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas seaborn scikit-learn imblearn pyyaml kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = '--kaggle_username--'\n",
    "os.environ['KAGGLE_KEY'] = '---key from kaggle---'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.utils as utils\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DATA['raw_dataset_path']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download using Kaggle API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"./creditcardfraud.zip\", 'r') as file:\n",
    "    file.extractall(\n",
    "        path=\"./data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(\"data/raw/creditcard.csv\", CONFIG_DATA['raw_dataset_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Membaca file raw \n",
    "2. Split data menjadi Train, Valid, Test\n",
    "3. Simpan data Train, Valid dan Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baca data CSV, simpan sebagai pickle\n",
    "CONFIG_DATA['raw_dataset_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "baca csv, simpan sebagai pickle. Format data yang lebih efisien. misal: csv 1 Gb jadi 0.5Gb. \n",
    "seringnya sih dari  database. data parquet lebih ok lagi sih; Pandas3 is optimized using parquet. more efficient\n",
    "'''\n",
    "\n",
    "CONFIG_DATA['data_set_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(return_file=True):\n",
    "    # Read data\n",
    "    data = pd.read_csv(CONFIG_DATA['raw_dataset_path'], \n",
    "                       sep=',',\n",
    "                    #    index_col=CONFIG_DATA['index_column'])\n",
    "    )\n",
    "    # Print data\n",
    "    print('data shape   :', data.shape)\n",
    "\n",
    "    # Dump data\n",
    "    utils.pickle_dump(data, CONFIG_DATA['data_set_path'])\n",
    "\n",
    "    # Return data\n",
    "    if return_file:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = features <br>\n",
    "y = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "waktu training perlu ada 2 input ke algoritma <br>\n",
    "1. feature\n",
    "2. label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_output(return_file=True):\n",
    "    # Read data\n",
    "    data = utils.pickle_load(CONFIG_DATA['data_set_path'])\n",
    "\n",
    "    # Split input & output\n",
    "    y = data[CONFIG_DATA['output_column']]\n",
    "    X = data.drop([CONFIG_DATA['output_column']], axis=1)\n",
    "\n",
    "    # Print splitting\n",
    "    print('Input shape  :', X.shape)\n",
    "    print('Output shape :', y.shape)\n",
    "    print('Input NAN    :')\n",
    "    print(X.isnull().sum())\n",
    "    print('Benchmark    :')\n",
    "    print(y.value_counts(normalize=True))\n",
    "    \n",
    "    # Dump file\n",
    "    utils.pickle_dump(X, CONFIG_DATA['input_set_path'])\n",
    "    utils.pickle_dump(y, CONFIG_DATA['output_set_path'])\n",
    "    utils.pickle_dump(X.columns, CONFIG_DATA['input_columns_path'])     # dump input columns\n",
    "\n",
    "    if return_file:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DATA['input_set_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DATA['test_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = melatih model <br>\n",
    "valid = optimize model <br>\n",
    "test = memilih model yang paling baik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 1 \n",
    "- training = 0.85\n",
    "- valid = 0.9\n",
    "\n",
    "model 2\n",
    "- training = 0.83\n",
    "- valid = 0.88\n",
    "\n",
    "menggunakan data test untuk memilih model paling bagus nilainya <br>\n",
    "\n",
    "model 1\n",
    "- test = 0.75\n",
    "model 2\n",
    "- test = 0.8\n",
    "\n",
    "kesimpulan : kita akan menggunakan model 2 sebagi model akhir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data raw 200.000 <br>\n",
    "data test = 20 % = 40.000 <br>\n",
    "data valid = 160.000 x 20% = 32.000 <br>\n",
    "data train = 200.000 - 40.000 - 32.000 = 138.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persentase test 10 - 25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(return_file=True):\n",
    "    # Load data\n",
    "    X = utils.pickle_load(CONFIG_DATA['input_set_path'])\n",
    "    y = utils.pickle_load(CONFIG_DATA['output_set_path'])\n",
    "\n",
    "    # Split test & rest (train & valid)\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \n",
    "                                            X,\n",
    "                                            y,\n",
    "                                            test_size = CONFIG_DATA['test_size'],\n",
    "                                            random_state = CONFIG_DATA['seed']\n",
    "                                        )\n",
    "    \n",
    "    # Split train & valid\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                            X_train,\n",
    "                                            y_train,\n",
    "                                            test_size = CONFIG_DATA['test_size'],\n",
    "                                            random_state = CONFIG_DATA['seed']\n",
    "                                        )\n",
    "    \n",
    "    # Print splitting\n",
    "    print('X_train shape :', X_train.shape)\n",
    "    print('y_train shape :', y_train.shape)\n",
    "    print('X_valid shape  :', X_valid.shape)\n",
    "    print('y_valid shape  :', y_valid.shape)\n",
    "    print('X_test shape  :', X_test.shape)\n",
    "    print('y_test shape  :', y_test.shape)\n",
    "\n",
    "    # Dump file\n",
    "    utils.pickle_dump(X_train, CONFIG_DATA['train_set_path'][0])\n",
    "    utils.pickle_dump(y_train, CONFIG_DATA['train_set_path'][1])\n",
    "    utils.pickle_dump(X_valid, CONFIG_DATA['valid_set_path'][0])\n",
    "    utils.pickle_dump(y_valid, CONFIG_DATA['valid_set_path'][1])\n",
    "    utils.pickle_dump(X_test, CONFIG_DATA['test_set_path'][0])\n",
    "    utils.pickle_dump(y_test, CONFIG_DATA['test_set_path'][1])\n",
    "\n",
    "    if return_file:\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_train_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "y_sample_0 = y_test[y_test==0].sample(10)\n",
    "y_sample_1 = y_test[y_test==1].sample(10)\n",
    "\n",
    "y_sample = pd.concat((y_sample_0, y_sample_1), axis=0)\n",
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test.loc[y_sample.index]\n",
    "X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample.to_csv('data/output/X_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample.to_csv('data/output/y_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
